# -*- coding: utf-8 -*-
"""
æ²ƒåœŸè§„åˆ’å¸ˆ - åŸºäºSparkçš„å†œä¸šç§æ¤é€‚å®œæ€§åŒºåˆ’ä¸ä¼˜åŒ–ç³»ç»Ÿ
é›†æˆMySQLæ•°æ®æºå’ŒEChartså¯è§†åŒ–
"""

from flask import Flask, render_template, request, jsonify
import pandas as pd
import json
import os
import numpy as np
from datetime import datetime
import logging
from real_data_connector import RealDataConnector
import threading
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'spark_agricultural_system_2024'

# å…¨å±€å˜é‡
spark_connector = None
analysis_results = None
system_status = "æœªåˆå§‹åŒ–"

# æ€§èƒ½ä¼˜åŒ–ç¼“å­˜
data_cache = {}
cache_lock = threading.Lock()
CACHE_TIMEOUT = 600  # 10åˆ†é’Ÿç¼“å­˜

def get_cache_key(endpoint, params=None):
    """ç”Ÿæˆç¼“å­˜é”®"""
    if params:
        param_str = json.dumps(params, sort_keys=True)
        return f"{endpoint}_{hash(param_str)}"
    return endpoint

def set_cache(key, data, timeout=CACHE_TIMEOUT):
    """è®¾ç½®ç¼“å­˜"""
    with cache_lock:
        data_cache[key] = {
            'data': data,
            'timestamp': time.time(),
            'timeout': timeout
        }

def get_cache(key):
    """è·å–ç¼“å­˜"""
    with cache_lock:
        if key in data_cache:
            cache_item = data_cache[key]
            if time.time() - cache_item['timestamp'] < cache_item['timeout']:
                return cache_item['data']
            else:
                del data_cache[key]
    return None

def compress_data(data):
    """å‹ç¼©æ•°æ®ç²¾åº¦"""
    def round_numbers(obj):
        if isinstance(obj, dict):
            return {k: round_numbers(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [round_numbers(item) for item in obj]
        elif isinstance(obj, float):
            return round(obj, 3)
        return obj
    return round_numbers(data)

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('spark_agricultural_index.html')

@app.route('/api/system/initialize', methods=['POST'])
def initialize_system():
    """åˆå§‹åŒ–Sparkç³»ç»Ÿ"""
    global spark_connector, system_status
    
    try:
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–Sparkå†œä¸šåˆ†æç³»ç»Ÿ...")
        system_status = "åˆå§‹åŒ–ä¸­"
        
        # åˆ›å»ºSparkè¿æ¥å™¨
        spark_connector = RealDataConnector()
        
        # è¯»å–æ•°æ®
        data = spark_connector.read_all_agricultural_data()
        if not data:
            system_status = "æ•°æ®è¯»å–å¤±è´¥"
            return jsonify({
                'status': 'error',
                'message': 'æ— æ³•è¯»å–MySQLæ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥'
            })
        
        system_status = "å°±ç»ª"
        logger.info("âœ… Sparkç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
        return jsonify({
            'status': 'success',
            'message': 'Sparkç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ',
            'data_summary': {
                'temperature_records': len(data['temperature']) if data['temperature'] is not None else 0,
                'precipitation_records': len(data['precipitation']) if data['precipitation'] is not None else 0,
                'soil_records': len(data['soil']) if data['soil'] is not None else 0,
                'crop_types': len(data['crop']) if data['crop'] is not None else 0
            }
        })
        
    except Exception as e:
        system_status = "åˆå§‹åŒ–å¤±è´¥"
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}'
        })

@app.route('/api/system/status')
def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    cache_key = get_cache_key('system_status')
    cached_result = get_cache(cache_key)
    if cached_result:
        return jsonify(cached_result)
    
    global system_status, spark_connector
    
    result = {
        'status': system_status,
        'spark_initialized': spark_connector is not None,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    set_cache(cache_key, result, 60)  # ç¼“å­˜1åˆ†é’Ÿ
    return jsonify(result)

@app.route('/api/analysis/run', methods=['POST'])
def run_comprehensive_analysis():
    """è¿è¡Œç»¼åˆåˆ†æ"""
    global spark_connector, analysis_results
    
    if not spark_connector:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆåˆå§‹åŒ–Sparkç³»ç»Ÿ'
        })
    
    try:
        start_time = time.time()
        
        # æ¸…é™¤ç¼“å­˜
        with cache_lock:
            data_cache.clear()
        
        logger.info("ğŸ”¬ å¼€å§‹è¿è¡Œç»¼åˆåˆ†æ...")
        
        # ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
        analysis_results = spark_connector.generate_comprehensive_report()
        
        if not analysis_results:
            return jsonify({
                'status': 'error',
                'message': 'åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§'
            })
        
        execution_time = time.time() - start_time
        
        # ç»Ÿè®¡åˆ†æç»“æœ
        stats = {
            'temperature_analysis': len(analysis_results.get('temperature', {})),
            'soil_analysis': len(analysis_results.get('soil', {})),
            'crop_analysis': len(analysis_results.get('crop', {})),
            'execution_time': round(execution_time, 2)
        }
        
        logger.info("âœ… ç»¼åˆåˆ†æå®Œæˆ")
        
        return jsonify({
            'status': 'success',
            'message': 'ç»¼åˆåˆ†æå®Œæˆ',
            'statistics': stats
        })
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'åˆ†æå¤±è´¥: {str(e)}'
        })

@app.route('/api/echarts/climate_trends')
def get_climate_trends():
    """è·å–æ°”å€™è¶‹åŠ¿EChartsæ•°æ®"""
    cache_key = get_cache_key('climate_trends')
    cached_result = get_cache(cache_key)
    if cached_result:
        return jsonify(cached_result)
    
    global analysis_results
    
    if not analysis_results or 'temperature' not in analysis_results:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆè¿è¡Œç»¼åˆåˆ†æ'
        })
    
    try:
        start_time = time.time()
        temp_data = analysis_results['temperature']
        
        # æœˆåº¦æ¸©åº¦è¶‹åŠ¿å›¾
        monthly_pattern = temp_data['monthly_pattern']
        temp_chart = {
            'title': 'æœˆåº¦æ¸©åº¦å˜åŒ–è¶‹åŠ¿',
            'xAxis': monthly_pattern['month_name'].tolist(),
            'series': [
                {
                    'name': 'å¹³å‡æ¸©åº¦',
                    'type': 'line',
                    'data': monthly_pattern['avg_temp'].tolist(),
                    'smooth': True
                }
            ]
        }
        
        # å¹´åº¦æ¸©åº¦è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        annual_trend = temp_data.get('annual_trend')
        annual_chart = {
            'title': 'å¹´åº¦æ¸©åº¦è¶‹åŠ¿',
            'xAxis': [],
            'series': []
        }
        
        if annual_trend is not None and not annual_trend.empty:
            annual_chart['xAxis'] = annual_trend['year_val'].tolist()
            annual_chart['series'] = [
                {
                    'name': 'å¹´å¹³å‡æ¸©åº¦',
                    'type': 'line',
                    'data': annual_trend['annual'].dropna().tolist(),
                    'smooth': True
                }
            ]
        
        # å­£èŠ‚æ¸©åº¦å¯¹æ¯”
        seasonal_chart = {
            'title': 'å­£èŠ‚æ¸©åº¦å¯¹æ¯”',
            'data': []
        }
        
        if annual_trend is not None and not annual_trend.empty:
            seasons = ['winter', 'spring', 'summer', 'autumn']
            season_names = ['å†¬å­£', 'æ˜¥å­£', 'å¤å­£', 'ç§‹å­£']
            
            for i, season in enumerate(seasons):
                if season in annual_trend.columns:
                    avg_temp = annual_trend[season].mean()
                    if not pd.isna(avg_temp):
                        seasonal_chart['data'].append({
                            'name': season_names[i],
                            'value': round(avg_temp, 2)
                        })
        
        processing_time = time.time() - start_time
        
        result = {
            'status': 'success',
            'charts': {
                'temperature_trend': temp_chart,
                'annual_trend': annual_chart,
                'seasonal_comparison': seasonal_chart
            },
            'processing_time': round(processing_time, 3)
        }
        
        # å‹ç¼©æ•°æ®
        result = compress_data(result)
        
        # ç¼“å­˜ç»“æœ
        set_cache(cache_key, result)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ æ°”å€™è¶‹åŠ¿æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'æ°”å€™è¶‹åŠ¿æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}'
        })

@app.route('/api/echarts/soil_analysis')
def get_soil_analysis():
    """è·å–åœŸå£¤åˆ†æEChartsæ•°æ®"""
    cache_key = get_cache_key('soil_analysis')
    cached_result = get_cache(cache_key)
    if cached_result:
        return jsonify(cached_result)
    
    global analysis_results
    
    if not analysis_results or 'soil' not in analysis_results:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆè¿è¡Œç»¼åˆåˆ†æ'
        })
    
    try:
        start_time = time.time()
        soil_data = analysis_results['soil']
        
        # åœŸå£¤ç±»å‹åˆ†å¸ƒé¥¼å›¾
        soil_type_dist = soil_data['soil_type_distribution']
        soil_type_summary = soil_type_dist.groupby('soil_type')['count'].sum().reset_index()
        
        soil_pie_data = []
        for _, row in soil_type_summary.iterrows():
            soil_pie_data.append({
                'name': row['soil_type'],
                'value': int(row['count'])
            })
        
        soil_pie_chart = {
            'title': 'åœŸå£¤ç±»å‹åˆ†å¸ƒ',
            'data': soil_pie_data
        }
        
        # pHå€¼åˆ†å¸ƒæŸ±çŠ¶å›¾
        ph_dist = soil_data['ph_distribution']
        ph_chart = {
            'title': 'pHå€¼åˆ†å¸ƒç»Ÿè®¡',
            'xAxis': ph_dist['ph_category'].tolist(),
            'series': [
                {
                    'name': 'æ ·æœ¬æ•°é‡',
                    'type': 'bar',
                    'data': ph_dist['count'].tolist()
                }
            ]
        }
        
        # å¿å¸‚åœŸå£¤è´¨é‡æ’å
        county_quality = soil_data['county_soil_quality'].head(15)  # å–å‰15å
        quality_chart = {
            'title': 'å¿å¸‚åœŸå£¤è´¨é‡æ’åï¼ˆå‰15åï¼‰',
            'xAxis': county_quality['county'].tolist(),
            'series': [
                {
                    'name': 'åœŸå£¤è´¨é‡è¯„åˆ†',
                    'type': 'bar',
                    'data': county_quality['soil_quality_score'].tolist()
                }
            ]
        }
        
        processing_time = time.time() - start_time
        
        result = {
            'status': 'success',
            'charts': {
                'soil_type_pie': soil_pie_chart,
                'ph_distribution': ph_chart,
                'county_quality_ranking': quality_chart
            },
            'processing_time': round(processing_time, 3)
        }
        
        # å‹ç¼©æ•°æ®
        result = compress_data(result)
        
        # ç¼“å­˜ç»“æœ
        set_cache(cache_key, result)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ åœŸå£¤åˆ†ææ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'åœŸå£¤åˆ†ææ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}'
        })

@app.route('/api/echarts/crop_suitability')
def get_crop_suitability():
    """è·å–ä½œç‰©é€‚å®œæ€§EChartsæ•°æ®"""
    cache_key = get_cache_key('crop_suitability')
    cached_result = get_cache(cache_key)
    if cached_result:
        return jsonify(cached_result)
    
    global analysis_results
    
    if not analysis_results or 'crop' not in analysis_results:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆè¿è¡Œç»¼åˆåˆ†æ'
        })
    
    try:
        start_time = time.time()
        crop_data = analysis_results['crop']
        
        # ä½œç‰©åˆ†ç±»é¥¼å›¾
        crop_categories = crop_data['crop_categories']
        category_pie_data = []
        for _, row in crop_categories.iterrows():
            category_pie_data.append({
                'name': row['category'],
                'value': int(row['total_varieties'])
            })
        
        category_pie_chart = {
            'title': 'ä½œç‰©åˆ†ç±»åˆ†å¸ƒ',
            'data': category_pie_data
        }
        
        # æ¸©åº¦éœ€æ±‚æŸ±çŠ¶å›¾
        temp_requirements = crop_data['temperature_requirements']
        if not temp_requirements.empty:
            temp_chart = {
                'title': 'ä½œç‰©æ¸©åº¦éœ€æ±‚èŒƒå›´',
                'xAxis': temp_requirements['crop_type'].head(10).tolist(),
                'series': [
                    {
                        'name': 'æœ€ä½æ¸©åº¦',
                        'type': 'bar',
                        'data': temp_requirements['min_temperature_min'].head(10).fillna(0).tolist()
                    },
                    {
                        'name': 'æœ€é«˜æ¸©åº¦',
                        'type': 'bar',
                        'data': temp_requirements['max_temperature_max'].head(10).fillna(30).tolist()
                    }
                ]
            }
        else:
            temp_chart = {
                'title': 'ä½œç‰©æ¸©åº¦éœ€æ±‚èŒƒå›´',
                'xAxis': [],
                'series': []
            }
        
        # pHéœ€æ±‚æ•£ç‚¹å›¾
        ph_requirements = crop_data['ph_requirements']
        if not ph_requirements.empty:
            ph_scatter_data = []
            for _, row in ph_requirements.head(20).iterrows():
                if pd.notna(row['ph_min']) and pd.notna(row['ph_max']):
                    ph_scatter_data.append([
                        float(row['ph_min']),
                        float(row['ph_max']),
                        row['crop_type']
                    ])
            
            ph_scatter_chart = {
                'title': 'ä½œç‰©pHéœ€æ±‚åˆ†å¸ƒ',
                'data': ph_scatter_data
            }
        else:
            ph_scatter_chart = {
                'title': 'ä½œç‰©pHéœ€æ±‚åˆ†å¸ƒ',
                'data': []
            }
        
        processing_time = time.time() - start_time
        
        result = {
            'status': 'success',
            'charts': {
                'suitability_distribution': category_pie_chart,
                'crop_advantages_radar': temp_chart,
                'limiting_factors_pie': ph_scatter_chart
            },
            'processing_time': round(processing_time, 3)
        }
        
        # å‹ç¼©æ•°æ®
        result = compress_data(result)
        
        # ç¼“å­˜ç»“æœ
        set_cache(cache_key, result)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ ä½œç‰©é€‚å®œæ€§æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'ä½œç‰©é€‚å®œæ€§æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}'
        })
        }
        
        # æœ€ä½³ç§æ¤åŒºåŸŸæ¨è
        best_areas = crop_data['best_planting_areas']
        
        # æŒ‰ä½œç‰©åˆ†ç»„åˆ¶ä½œé›·è¾¾å›¾
        radar_data = {}
        radar_indicator = [
            {'name': 'é€‚å®œé¢ç§¯', 'max': best_areas['suitable_points'].max()},
            {'name': 'å¹³å‡é€‚å®œæ€§', 'max': 1},
            {'name': 'åŒºåŸŸé›†ä¸­åº¦', 'max': 1}
        ]
        
        for crop in crops:
            crop_areas = best_areas[best_areas['crop_name'] == crop].head(5)
            if not crop_areas.empty:
                radar_data[crop] = [
                    float(crop_areas['suitable_points'].mean()),
                    float(crop_areas['avg_suitability'].mean()),
                    float(len(crop_areas) / 10)  # æ ‡å‡†åŒ–åŒºåŸŸé›†ä¸­åº¦
                ]
        
        radar_chart = {
            'title': 'ä½œç‰©ç§æ¤ä¼˜åŠ¿é›·è¾¾å›¾',
            'indicator': radar_indicator,
            'data': radar_data
        }
        
        # é™åˆ¶å› å­åˆ†æé¥¼å›¾
        limiting_factors = crop_data['limiting_factors']
        factor_summary = limiting_factors.groupby('limiting_factor')['affected_areas'].sum().reset_index()
        
        factor_pie_data = []
        for _, row in factor_summary.iterrows():
            factor_pie_data.append({
                'name': row['limiting_factor'],
                'value': int(row['affected_areas'])
            })
        
        limiting_factors_chart = {
            'title': 'ç§æ¤é™åˆ¶å› å­åˆ†æ',
            'data': factor_pie_data
        }
        
        processing_time = time.time() - start_time
        
        result = {
            'status': 'success',
            'charts': {
                'suitability_distribution': suitability_chart,
                'crop_advantages_radar': radar_chart,
                'limiting_factors_pie': limiting_factors_chart
            },
            'processing_time': round(processing_time, 3)
        }
        
        # å‹ç¼©æ•°æ®
        result = compress_data(result)
        
        # ç¼“å­˜ç»“æœ
        set_cache(cache_key, result)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ ä½œç‰©é€‚å®œæ€§æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'ä½œç‰©é€‚å®œæ€§æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}'
        })

@app.route('/api/echarts/zoning_optimization')
def get_zoning_optimization():
    """è·å–åŒºåˆ’ä¼˜åŒ–EChartsæ•°æ®"""
    cache_key = get_cache_key('zoning_optimization')
    cached_result = get_cache(cache_key)
    if cached_result:
        return jsonify(cached_result)
    
    global analysis_results
    
    if not analysis_results or 'crop' not in analysis_results:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆè¿è¡Œç»¼åˆåˆ†æ'
        })
    
    try:
        start_time = time.time()
        crop_data = analysis_results['crop']
        
        # åŒºåˆ’ä¼˜åŒ–æ•£ç‚¹å›¾
        zoning_data = crop_data['zoning_optimization']
        
        scatter_series = []
        crops = zoning_data['crop_name'].unique()
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
        
        for i, crop in enumerate(crops):
            crop_zones = zoning_data[zoning_data['crop_name'] == crop]
            scatter_data = []
            
            for _, row in crop_zones.iterrows():
                scatter_data.append([
                    float(row['zone_center_lon']),
                    float(row['zone_center_lat']),
                    float(row['avg_suitability']),
                    int(row['grid_count']),
                    str(row['zone_id'])
                ])
            
            scatter_series.append({
                'name': crop,
                'type': 'scatter',
                'data': scatter_data,
                'symbolSize': lambda params: max(5, min(30, params[3] / 10)),
                'itemStyle': {
                    'color': colors[i % len(colors)]
                }
            })
        
        zoning_scatter = {
            'title': 'åŒºåˆ’ä¼˜åŒ–åˆ†å¸ƒå›¾',
            'series': scatter_series
        }
        
        # æœ€ä½³ç§æ¤åŒºåŸŸåœ°å›¾æ•°æ®
        best_areas = crop_data['best_planting_areas']
        
        map_series = []
        for crop in crops:
            crop_areas = best_areas[best_areas['crop_name'] == crop].head(10)
            map_data = []
            
            for _, row in crop_areas.iterrows():
                map_data.append([
                    float(row['center_lon']),
                    float(row['center_lat']),
                    float(row['avg_suitability']),
                    row['county']
                ])
            
            map_series.append({
                'name': crop,
                'type': 'scatter',
                'coordinateSystem': 'geo',
                'data': map_data,
                'symbolSize': 8,
                'itemStyle': {
                    'color': colors[crops.tolist().index(crop) % len(colors)]
                }
            })
        
        optimization_map = {
            'title': 'æœ€ä½³ç§æ¤åŒºåŸŸåˆ†å¸ƒ',
            'series': map_series,
            'geo': {
                'map': 'china',
                'roam': True,
                'zoom': 1.2,
                'center': [112, 27.5],
                'itemStyle': {
                    'areaColor': '#f0f0f0',
                    'borderColor': '#999'
                }
            }
        }
        
        processing_time = time.time() - start_time
        
        result = {
            'status': 'success',
            'charts': {
                'zoning_scatter': zoning_scatter,
                'optimization_map': optimization_map
            },
            'processing_time': round(processing_time, 3)
        }
        
        # å‹ç¼©æ•°æ®
        result = compress_data(result)
        
        # ç¼“å­˜ç»“æœ
        set_cache(cache_key, result)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ åŒºåˆ’ä¼˜åŒ–æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'åŒºåˆ’ä¼˜åŒ–æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}'
        })

@app.route('/api/report/export')
def export_analysis_report():
    """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
    global analysis_results
    
    if not analysis_results:
        return jsonify({
            'status': 'error',
            'message': 'è¯·å…ˆè¿è¡Œç»¼åˆåˆ†æ'
        })
    
    try:
        # ç”ŸæˆæŠ¥å‘Šæ‘˜è¦
        report_summary = {
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'system': 'æ²ƒåœŸè§„åˆ’å¸ˆ - Sparkå†œä¸šåˆ†æç³»ç»Ÿ',
            'data_sources': 'MySQLæ•°æ®åº“',
            'analysis_modules': ['æ°”å€™è¶‹åŠ¿åˆ†æ', 'åœŸå£¤åˆ†å¸ƒåˆ†æ', 'ä½œç‰©é€‚å®œæ€§åˆ†æ', 'åŒºåˆ’ä¼˜åŒ–å»ºè®®']
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        statistics = {}
        if 'climate' in analysis_results:
            climate_data = analysis_results['climate']
            statistics['climate'] = {
                'temperature_records': len(climate_data['temperature_trend']),
                'precipitation_records': len(climate_data['precipitation_pattern']),
                'regional_zones': len(climate_data['regional_climate'])
            }
        
        if 'soil' in analysis_results:
            soil_data = analysis_results['soil']
            statistics['soil'] = {
                'soil_types': len(soil_data['soil_type_distribution']['soil_type'].unique()),
                'counties_analyzed': len(soil_data['county_soil_quality']),
                'ph_categories': len(soil_data['ph_distribution'])
            }
        
        if 'crop' in analysis_results:
            crop_data = analysis_results['crop']
            statistics['crop'] = {
                'crop_varieties': len(crop_data['crop_suitability_stats']['crop_name'].unique()),
                'suitable_areas': len(crop_data['best_planting_areas']),
                'optimization_zones': len(crop_data['zoning_optimization'])
            }
        
        return jsonify({
            'status': 'success',
            'report': {
                'summary': report_summary,
                'statistics': statistics
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
        return jsonify({
            'status': 'error',
            'message': f'å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {str(e)}'
        })

if __name__ == '__main__':
    print("ğŸŒ± æ²ƒåœŸè§„åˆ’å¸ˆ - Sparkå†œä¸šåˆ†æç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    print("ğŸ”— è®¿é—®åœ°å€: http://localhost:5003")
    print("ğŸ“Š åŠŸèƒ½æ¨¡å—: Sparkæ•°æ®åˆ†æ + EChartså¯è§†åŒ–")
    print("ğŸ—„ï¸ æ•°æ®æº: MySQLæ•°æ®åº“")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=5003, debug=True)
